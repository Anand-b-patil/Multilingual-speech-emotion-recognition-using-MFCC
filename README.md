

<<<<<<< Updated upstream
# ğŸŒ Multilingual Speech Emotion Recognition ğŸ™ï¸ğŸ§ 
=======
##Project Overview
>>>>>>> Stashed changes

A machine learning and deep learning-based project for detecting emotions from speech across **multiple languages** using advanced **audio processing** and **neural network architectures**.

<<<<<<< Updated upstream
---
=======
##Features
>>>>>>> Stashed changes

## ğŸ“Œ Project Overview

This project classifies emotions from speech audio samples across various languages. It extracts powerful acoustic features (MFCCs, Chroma, Mel Spectrograms) and applies both **machine learning** and **deep learning** models to recognize emotions like happiness, sadness, anger, and neutrality.

---

## ğŸš€ Features

* âœ… Multilingual support (English, Spanish, French, etc.)
* âœ… Emotion detection: **Happy**, **Sad**, **Angry**, **Neutral**, etc.
* âœ… Advanced audio feature extraction using `Librosa`
* âœ… ML Models: SVM, Random Forest, XGBoost
* âœ… DL Models: CNN, LSTM, Transformers
* âœ… Scalable for **real-time** emotion detection applications

<<<<<<< Updated upstream
---
=======
##Datasets
>>>>>>> Stashed changes

## ğŸ“‚ Dataset

<<<<<<< Updated upstream
* **Toronto Emotional Speech Set (TESS)**
  Includes speech samples from two female actors, simulating various emotions across multiple sentences.

---

## ğŸ› ï¸ Installation
=======
##Installation
>>>>>>> Stashed changes

Clone the repository:

```bash
git clone https://github.com/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC.git
cd Multilingual-speech-emotion-recognition-using-MFCC
```

Install the dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ¼ Feature Extraction

Features are extracted using **Librosa**:

* ğŸµ **MFCC** (Mel Frequency Cepstral Coefficients)
* ğŸ¼ **Chroma Frequencies**
* ğŸŒˆ **Mel Spectrograms**

---

## ğŸ§  Models Used

### ğŸ›  Machine Learning Models

* ğŸ”¹ Support Vector Machine (SVM)
* ğŸ”¹ Random Forest
* ğŸ”¹ XGBoost

### ğŸ¤– Deep Learning Models

* ğŸ§± Convolutional Neural Networks (CNN)
* â³ Long Short-Term Memory (LSTM)
* ğŸ§  Transformer-based Architectures

---

## ğŸ“Š Results

* âœ… High accuracy for emotion detection across languages
* ğŸ”¬ Robust performance on multiple datasets
* ğŸš€ Ready for future **real-time deployment** potential

---

## ğŸ¯ Sample Prediction Outputs

<div align="center">
  <img src="static/home_page.png" alt="Home Page" width="600"/>
  <br/>
  <em>Emotion Prediction Interface</em>
</div>

<div align="center">
  <img src="static/result_page.png" alt="Result Page" width="600"/>
  <br/>
  <em>Prediction Results Display</em>
</div>

````markdown

# ğŸŒ Multilingual Speech Emotion Recognition ğŸ™ï¸ğŸ§ 

A machine learning and deep learning project for detecting emotions from speech across multiple languages using advanced audio processing and neural network architectures.

---

## ï¿½ Project Overview

This project classifies emotions from speech audio samples across various languages. It extracts acoustic features (MFCCs, Chroma, Mel Spectrograms) and applies both machine learning and deep learning models to recognize emotions like happiness, sadness, anger, and neutrality.

---

## ï¿½ Features

* Multilingual support (English, Spanish, French, etc.)
* Emotion detection: Happy, Sad, Angry, Neutral, Surprise, Disgust, Fear
* Audio feature extraction using `librosa`
* ML Models: SVM, Random Forest, XGBoost
* DL Models: CNN, LSTM, Transformer-based architectures
* Ready for extension to real-time emotion detection

---

## ğŸ“‚ Dataset

* Toronto Emotional Speech Set (TESS) â€” samples from multiple actors covering several emotions

---

## ğŸ› ï¸ Installation

Clone the repository and install dependencies:

```powershell
git clone https://github.com/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC.git
cd Multilingual-speech-emotion-recognition-using-MFCC
pip install -r requirements.txt
```

---

## ğŸ¼ Feature Extraction

Features are extracted using `librosa`:

* MFCC (Mel Frequency Cepstral Coefficients)
* Chroma Frequencies
* Mel Spectrograms

---

## ğŸ§  Models Used

### Machine Learning Models
* Support Vector Machine (SVM)
* Random Forest
* XGBoost

### Deep Learning Models
* Convolutional Neural Networks (CNN)
* Long Short-Term Memory (LSTM)
* Transformer-based Architectures

---

## ğŸ“Š Results

The project demonstrates competitive accuracy across selected datasets and is structured for future improvements towards real-time deployment.

---

## ğŸ¯ Sample Prediction Outputs

<div align="center">
  <img src="static/home_page.png" alt="Home Page" width="600"/>
  <br/>
  <em>Emotion Prediction Interface</em>
</div>

<div align="center">
  <img src="static/result_page.png" alt="Result Page" width="600"/>
  <br/>
  <em>Prediction Results Display</em>
</div>

---

## ğŸ§­ Future Improvements

* Add real-time streaming audio emotion detection
* Expand dataset to include more languages and speakers
* Optimize deep models for lower-latency inference

---

## ğŸ“¦ Tech Stack & Libraries

| Tool         | Version |
| ------------ | ------- |
| Python       | 3.8+    |
| NumPy        | 1.24+   |
| Pandas       | 1.5+    |
| Librosa      | 0.10+   |
| scikit-learn | 1.2+    |
| XGBoost      | 1.7+    |
| TensorFlow   | 2.x     |
| Matplotlib   | 3.x     |

---

## ğŸ“œ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ™Œ Acknowledgements

* TESS Dataset â€” Toronto Emotional Speech Set
* Librosa â€” audio analysis
* TensorFlow & scikit-learn â€” modeling

````
