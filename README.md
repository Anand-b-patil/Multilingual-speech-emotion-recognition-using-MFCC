🌍 Multilingual Speech Emotion Recognition 🎙️🧠
A machine learning and deep learning-based project for detecting emotions from speech across multiple languages using advanced audio processing techniques.

📌 Project Overview
This project focuses on classifying emotions from speech audio samples across multiple languages. It leverages key acoustic features and cutting-edge machine learning and deep learning models for multilingual emotion classification.

🚀 Features
✅ Supports multiple languages (e.g., English, Spanish, French).
✅ Detects various emotions: happy, sad, angry, neutral, etc.
✅ Utilizes MFCC, Chroma, and Mel Spectrograms for feature extraction.
✅ Implements CNN, LSTM, and Transformer-based deep learning models.
✅ Designed to be extensible for real-time emotion detection.

📂 Dataset
The project uses the Toronto Emotional Speech Set (TESS), which contains speech samples from two female actors simulating different emotions while reading predefined sentences.

🛠️ Installation
Clone the repository:

git clone https://github.com/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC.git
cd Multilingual-speech-emotion-recognition-using-MFCC

Install required dependencies:

pip install -r requirements.txt

🧪 Model Training & Evaluation
🎼 Feature Extraction
MFCC (Mel Frequency Cepstral Coefficients)

Chroma Frequencies

Mel Spectrograms

All features are extracted using Librosa.

🧠 Machine Learning Models
Support Vector Machine (SVM)

Random Forest

XGBoost

🤖 Deep Learning Models
Convolutional Neural Networks (CNN)

Long Short-Term Memory Networks (LSTM)

Transformer-based models
![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![License](https://img.shields.io/github/license/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC)
![Last Commit](https://img.shields.io/github/last-commit/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC)
![Issues](https://img.shields.io/github/issues/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC)
![Stars](https://img.shields.io/github/stars/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC?style=social)

📈 Results
The models achieve high accuracy across different emotions and languages.

Demonstrated potential for real-time multilingual emotion detection.


🚧 Future Improvements
🔄 Real-time emotion recognition integration using streaming audio input.

🌐 Expand dataset to include more languages and speakers.

⚡ Optimize models for faster inference and deployment.

📜 License
This project is licensed under the MIT License — see the LICENSE file for details.

🙌 Acknowledgements
TESS Dataset - Toronto Emotional Speech Set

Librosa

Keras

Scikit-learn

