ğŸŒ Multilingual Speech Emotion Recognition ğŸ™ï¸ğŸ§ 
A machine learning and deep learning-based project for detecting emotions from speech across multiple languages using advanced audio processing techniques.

ğŸ“Œ Project Overview
This project focuses on classifying emotions from speech audio samples across multiple languages. It leverages key acoustic features and cutting-edge machine learning and deep learning models for multilingual emotion classification.

ğŸš€ Features
âœ… Supports multiple languages (e.g., English, Spanish, French).
âœ… Detects various emotions: happy, sad, angry, neutral, etc.
âœ… Utilizes MFCC, Chroma, and Mel Spectrograms for feature extraction.
âœ… Implements CNN, LSTM, and Transformer-based deep learning models.
âœ… Designed to be extensible for real-time emotion detection.

ğŸ“‚ Dataset
The project uses the Toronto Emotional Speech Set (TESS), which contains speech samples from two female actors simulating different emotions while reading predefined sentences.

ğŸ› ï¸ Installation
Clone the repository:

git clone https://github.com/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC.git
cd Multilingual-speech-emotion-recognition-using-MFCC

Install required dependencies:

pip install -r requirements.txt

ğŸ§ª Model Training & Evaluation
ğŸ¼ Feature Extraction
MFCC (Mel Frequency Cepstral Coefficients)

Chroma Frequencies

Mel Spectrograms

All features are extracted using Librosa.

ğŸ§  Machine Learning Models
Support Vector Machine (SVM)

Random Forest

XGBoost

ğŸ¤– Deep Learning Models
Convolutional Neural Networks (CNN)

Long Short-Term Memory Networks (LSTM)

Transformer-based models
![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![License](https://img.shields.io/github/license/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC)
![Last Commit](https://img.shields.io/github/last-commit/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC)
![Issues](https://img.shields.io/github/issues/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC)
![Stars](https://img.shields.io/github/stars/Anand-b-patil/Multilingual-speech-emotion-recognition-using-MFCC?style=social)

ğŸ“ˆ Results
The models achieve high accuracy across different emotions and languages.

Demonstrated potential for real-time multilingual emotion detection.


ğŸš§ Future Improvements
ğŸ”„ Real-time emotion recognition integration using streaming audio input.

ğŸŒ Expand dataset to include more languages and speakers.

âš¡ Optimize models for faster inference and deployment.

ğŸ“œ License
This project is licensed under the MIT License â€” see the LICENSE file for details.

ğŸ™Œ Acknowledgements
TESS Dataset - Toronto Emotional Speech Set

Librosa

Keras

Scikit-learn

